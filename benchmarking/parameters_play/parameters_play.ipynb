{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing health check on http://localhost:11434\n",
      "Ollama is running\n",
      "Health check passed\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import os\n",
    "import json_tricks as json\n",
    "dotenv_path = os.path.abspath(\"../../backend/.env\")\n",
    "if os.path.exists(dotenv_path):\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv(dotenv_path)\n",
    "    \n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"../../..\")\n",
    "from backend.LLM.AnythingLLM_client import AnythingLLMClient\n",
    "from backend.Generater import Generater\n",
    "from backend.LLM.OllamaLLM import OllamaAI\n",
    "from backend.database.schemas import Email\n",
    "\n",
    "\n",
    "anyllm_client = AnythingLLMClient(\"http://localhost:3001/api\", \"3WMNAPZ-GYH4RBE-M67SR00-7Y7KYEF\")\n",
    "ollama_client = OllamaAI('http://localhost:11434', 'llama3:instruct')\n",
    "generator = Generater(ollama_client, anyllm_client)\n",
    "path_to_dataset = os.path.abspath(\"../../dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play with temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_refuse = \"Cannot answer\"\n",
    "workspace_slug = anyllm_client.get_workspace_slug(\"temperature_play\")\n",
    "\n",
    "for enquiry in os.listdir(path_to_dataset)[:1]:\n",
    "    if not enquiry.endswith(\".json\") or not \"fake\" in enquiry:\n",
    "        continue\n",
    "        \n",
    "    with open(os.path.join(path_to_dataset, enquiry), \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    questions = data[\"questions\"]\n",
    "    results = []\n",
    "    for i in range(len(questions)):\n",
    "        question = data[\"questions\"][i][\"question\"]\n",
    "        temperature = 1\n",
    "        for reducer in range(0, 10, 1):\n",
    "            temperature = round(1 - round(reducer/10, 1), 1)\n",
    "            print(f\"Temperature: {temperature}\")\n",
    "            anyllm_client.update_workspace(workspace_slug, { \"openAiTemp\": temperature })\n",
    "            new_thread = anyllm_client.new_thread(workspace_slug, f\"temp_{temperature}\")\n",
    "            new_thread_slug = new_thread[\"slug\"]\n",
    "            res = anyllm_client.chat_with_thread(workspace_slug, new_thread_slug, question)\n",
    "            results.append({\n",
    "                \"temperature\": temperature,\n",
    "                \"response\": res[\"textResponse\"]\n",
    "            })\n",
    "            anyllm_client.delete_thread(workspace_slug, new_thread_slug)\n",
    "            \n",
    "path_results = \"results.json\"\n",
    "with open(path_results, \"w\") as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_refuse = \"Cannot answer\"\n",
    "workspace_slug = anyllm_client.get_workspace_slug(\"temperature_play\")\n",
    "\n",
    "for enquiry in os.listdir(path_to_dataset)[:1]:\n",
    "    if not enquiry.endswith(\".json\") or not \"fake\" in enquiry:\n",
    "        continue\n",
    "        \n",
    "    with open(os.path.join(path_to_dataset, enquiry), \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    questions = data[\"questions\"]\n",
    "    results = []\n",
    "    for i in range(len(questions)):\n",
    "        question = data[\"questions\"][i][\"question\"]\n",
    "\n",
    "        for reducer in range(4, -1, -1):\n",
    "            similarityThreshold = 1 - (reducer/4) \n",
    "            print(f\"similarityThreshold: {similarityThreshold}\")\n",
    "            anyllm_client.update_workspace(workspace_slug, { \"similarityThreshold\": similarityThreshold })\n",
    "            new_thread = anyllm_client.new_thread(workspace_slug, f\"sim_{similarityThreshold}\")\n",
    "            new_thread_slug = new_thread[\"slug\"]\n",
    "            res = anyllm_client.chat_with_thread(workspace_slug, new_thread_slug, question)\n",
    "            results.append({\n",
    "                \"similarityThreshold\": similarityThreshold,\n",
    "                \"response\": res[\"textResponse\"],\n",
    "                \"sources\": res[\"sources\"]\n",
    "            })\n",
    "            anyllm_client.delete_thread(workspace_slug, new_thread_slug)\n",
    "            \n",
    "path_results = \"results_sim.json\"\n",
    "with open(path_results, \"w\") as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "rules = [\n",
    "    \"Call by their last name\",\n",
    "    \"Change the tone to be professional\",\n",
    "    \"Greetings depend on the time of the day\",\n",
    "]\n",
    "\n",
    "paramters = {\n",
    "    \"today\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "    \"rules\": rules\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new thread with name: rules in workspace: temperature_play\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query_refuse = \"Cannot answer\"\n",
    "workspace_slug = anyllm_client.get_workspace_slug(\"temperature_play\")\n",
    "anyllm_client.update_workspace(workspace_slug, { \"similarityThreshold\": 0.5 })\n",
    "\n",
    "for enquiry in os.listdir(path_to_dataset)[:1]:\n",
    "    if not enquiry.endswith(\".json\") or not \"fake\" in enquiry:\n",
    "        continue\n",
    "        \n",
    "    with open(os.path.join(path_to_dataset, enquiry), \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    results = []\n",
    "    email = data[\"email\"]\n",
    "    \n",
    "    prompt= f\"\"\"\n",
    "        You are David Frischer, the program administrator for the Software Engineering program.\n",
    "        You have received an email from a student:\n",
    "        \n",
    "        {email}\n",
    "        \n",
    "        Reply to the student's email with the following rules:\n",
    "        {json.dumps(paramters)}\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "    \n",
    "\n",
    "    new_thread = anyllm_client.new_thread(workspace_slug, f\"rules\")\n",
    "    new_thread_slug = new_thread[\"slug\"]\n",
    "    res = anyllm_client.chat_with_thread(workspace_slug, new_thread_slug, prompt)\n",
    "    results.append({\n",
    "        \"response\": res[\"textResponse\"],\n",
    "        \"sources\": res[\"sources\"]\n",
    "    })\n",
    "        \n",
    "        \n",
    "        \n",
    "    # anyllm_client.delete_thread(workspace_slug, new_thread_slug)\n",
    "            \n",
    "path_results = \"results_rules.json\"\n",
    "with open(path_results, \"w\") as f:\n",
    "    json.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
