{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing health check on http://localhost:11434\n",
      "Ollama is running\n",
      "Health check passed\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import os\n",
    "import json\n",
    "from pydantic.json import pydantic_encoder\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../../backend/.env')\n",
    "sys.path.append(\"../../\")\n",
    "from backend.LLM.AnythingLLM_client import AnythingLLMClient\n",
    "from backend.Reviewer import Reviewer\n",
    "from backend.LLM.OllamaLLM import OllamaAI\n",
    "from backend.database.schemas import DraftResult\n",
    "\n",
    "\n",
    "anyllm_client = AnythingLLMClient(\"http://localhost:3001/api\", \"3WMNAPZ-GYH4RBE-M67SR00-7Y7KYEF\")\n",
    "ollama_client = OllamaAI('http://localhost:11434', 'llama3:instruct')\n",
    "reviewer = Reviewer(ollama_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../dataset/fake_email_10.json\n",
      "../../dataset/fake_email_undergrad_18.json\n",
      "../../dataset/fake_email_undergrad_3.json\n",
      "the JSON object must be str, bytes or bytearray, not NoneType\n",
      "../../dataset/fake_email_3.json\n",
      "../../dataset/fake_email_undergrad_14.json\n",
      "../../dataset/fake_email_undergrad_15.json\n",
      "../../dataset/fake_email_2.json\n",
      "../../dataset/fake_email_undergrad_2.json\n",
      "../../dataset/fake_email_undergrad_19.json\n",
      "../../dataset/fake_email_11.json\n",
      "../../dataset/fake_email_undergrad_12.json\n",
      "../../dataset/fake_email_9.json\n",
      "../../dataset/fake_email_16.json\n",
      "../../dataset/fake_email_5.json\n",
      "../../dataset/fake_email_4.json\n",
      "../../dataset/fake_email_17.json\n",
      "../../dataset/fake_email_8.json\n",
      "../../dataset/fake_email_undergrad_13.json\n",
      "../../dataset/fake_email_18.json\n",
      "../../dataset/fake_email_7.json\n",
      "../../dataset/fake_email_undergrad_7.json\n",
      "the JSON object must be str, bytes or bytearray, not NoneType\n",
      "../../dataset/fake_email_14.json\n",
      "../../dataset/fake_email_15.json\n",
      "../../dataset/fake_email_undergrad_6.json\n",
      "../../dataset/fake_email_19.json\n",
      "the JSON object must be str, bytes or bytearray, not NoneType\n",
      "../../dataset/fake_email_undergrad_1.json\n",
      "../../dataset/fake_email_undergrad_16.json\n",
      "../../dataset/fake_email_undergrad_17.json\n",
      "../../dataset/fake_email_undergrad_0.json\n"
     ]
    }
   ],
   "source": [
    "drafts_generated_path = \"../one_vs_multi_shots/results\"\n",
    "path_to_emails = \"../../dataset\"\n",
    "method = \"single_shot\"\n",
    "\n",
    "already_evaluated = os.listdir(\"results\")\n",
    "    \n",
    "for draft_file in os.listdir(drafts_generated_path):\n",
    "    \n",
    "    if draft_file in already_evaluated:\n",
    "        print(f\"Already evaluated {draft_file}\")\n",
    "        continue\n",
    "    \n",
    "    with open(f\"{drafts_generated_path}/{draft_file}\", 'r') as f:\n",
    "        draft_generated_data = json.load(f)\n",
    "        response_email = draft_generated_data[method]['response']['textResponse']\n",
    "        sources = draft_generated_data[method]['response']['sources']    \n",
    "        \n",
    "    enquiry_path = f\"{path_to_emails}/{draft_file.replace('results_', '')}\"\n",
    "    print(enquiry_path)\n",
    "    with open(enquiry_path, 'r') as f:\n",
    "        email_data = json.load(f)\n",
    "        email = email_data['email']\n",
    "    \n",
    "    \n",
    "    base_prompt = f\"\"\"\n",
    "    From this enquiry:\n",
    "    Enquiry: {email}\n",
    "    ---\n",
    "    Does the response answer the enquiry?\n",
    "    Response: {response_email}\n",
    "    ---\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    start_time_linkert = time.time()\n",
    "    linkert_score = reviewer.linkert_eval(base_prompt)\n",
    "    end_time_linkert = time.time()\n",
    "    \n",
    "    start_time_hallucination = time.time()\n",
    "    draft_score = reviewer.hallucination_eval(base_prompt, sources)\n",
    "    end_time_hallucination = time.time()\n",
    "    \n",
    "    results_path = f\"results/reviewer_{draft_file}\"\n",
    "    \n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump({\n",
    "            \"linkert_score\": linkert_score,\n",
    "            \"hallucination_score\": draft_score,\n",
    "            \"linkert_time\": end_time_linkert - start_time_linkert,\n",
    "            \"hallucination_time\": end_time_hallucination - start_time_hallucination\n",
    "        }, f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "already_evaluated = os.listdir(\"results\")\n",
    "markdowns_path = \"markdowns\"\n",
    "os.makedirs(markdowns_path, exist_ok=True)\n",
    "\n",
    "for draft_file in os.listdir(drafts_generated_path):\n",
    "    filename = f\"reviewer_results_{draft_file}\"\n",
    "    if f\"{filename}\" not in already_evaluated:\n",
    "        print(f\"not evaluated {filename}\")\n",
    "        continue\n",
    "    \n",
    "    with open(f\"{drafts_generated_path}/{draft_file}\", 'r') as f:\n",
    "        draft_generated_data = json.load(f)\n",
    "        response_email = draft_generated_data[method]['response']['textResponse']\n",
    "        sources = draft_generated_data[method]['response']['sources']    \n",
    "        \n",
    "    enquiry_path = f\"{path_to_emails}/{draft_file.replace('results_', '')}\"\n",
    "    with open(enquiry_path, 'r') as f:\n",
    "        email_data = json.load(f)\n",
    "        email = email_data['email']\n",
    "    \n",
    "    with open(f\"{markdowns_path}/human_reviewer_{draft_file.replace(\".json\", \".md\")}\", 'w') as f:\n",
    "        # email and response in the markdown \n",
    "        text = f\"\"\"\n",
    "# Enquiry {draft_file}\n",
    "\n",
    "{email}\n",
    "\n",
    "# Response\n",
    "\n",
    "{response_email}\n",
    "\n",
    "        \"\"\"\n",
    "        f.write(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
